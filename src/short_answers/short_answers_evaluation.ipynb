{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DebertaForQuestionAnswering, RobertaForQuestionAnswering\n",
    "from short_answer_dataset import ShortAnswerDataset\n",
    "import json\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def evaluate(model, val_data, batch_size=4, max_length=512, max_answers=3):\n",
    "    val_dataset = ShortAnswerDataset(val_data, max_length=max_length, max_answers=max_answers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    predictions_dict = {}\n",
    "    true_answers_dict = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            example_ids = batch['example_id']\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                start_positions=start_positions,\n",
    "                end_positions=end_positions\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(\"Non-finite loss encountered during evaluation.\")\n",
    "                continue  \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "\n",
    "            start_preds = torch.argmax(start_logits, dim=-1)\n",
    "            end_preds = torch.argmax(end_logits, dim=-1)\n",
    "\n",
    "            for i in range(len(example_ids)):\n",
    "                example_id = example_ids[i].item() if isinstance(example_ids[i], torch.Tensor) else example_ids[i]\n",
    "                pred_span = (start_preds[i].item(), end_preds[i].item())\n",
    "                true_span = (start_positions[i].item(), end_positions[i].item())\n",
    "\n",
    "                # Collect all predictions per example_id\n",
    "                if example_id in predictions_dict:\n",
    "                    predictions_dict[example_id].append(pred_span)\n",
    "                else:\n",
    "                    predictions_dict[example_id] = [pred_span]\n",
    "\n",
    "                # Collect all true spans per example_id\n",
    "                if example_id in true_answers_dict:\n",
    "                    true_answers_dict[example_id].append(true_span)\n",
    "                else:\n",
    "                    true_answers_dict[example_id] = [true_span]\n",
    "\n",
    "    all_em = []\n",
    "    all_f1 = []\n",
    "    all_precision = []\n",
    "    all_recall = []\n",
    "\n",
    "    for example_id in predictions_dict:\n",
    "        pred_spans = predictions_dict[example_id]\n",
    "        true_spans = true_answers_dict[example_id]\n",
    "\n",
    "        max_em = 0\n",
    "        max_f1 = 0\n",
    "        max_precision = 0\n",
    "        max_recall = 0\n",
    "\n",
    "        for pred_span in pred_spans:\n",
    "            for true_span in true_spans:\n",
    "                em = exact_match_score(pred_span, true_span)\n",
    "                f1 = f1_score(pred_span, true_span)\n",
    "                precision = precision_score(pred_span, true_span)\n",
    "                recall = recall_score(pred_span, true_span)\n",
    "\n",
    "                max_em = max(max_em, em)\n",
    "                max_f1 = max(max_f1, f1)\n",
    "                max_precision = max(max_precision, precision)\n",
    "                max_recall = max(max_recall, recall)\n",
    "\n",
    "        all_em.append(max_em)\n",
    "        all_f1.append(max_f1)\n",
    "        all_precision.append(max_precision)\n",
    "        all_recall.append(max_recall)\n",
    "\n",
    "    em = sum(all_em) / len(all_em) if len(all_em) > 0 else 0\n",
    "    f1 = sum(all_f1) / len(all_f1) if len(all_f1) > 0 else 0\n",
    "    precision = sum(all_precision) / len(all_precision) if len(all_precision) > 0 else 0\n",
    "    recall = sum(all_recall) / len(all_recall) if len(all_recall) > 0 else 0\n",
    "\n",
    "    return epoch_loss / len(val_loader), em, f1, precision, recall\n",
    "\n",
    "def exact_match_score(pred_span, true_span):\n",
    "    return int(pred_span == true_span)\n",
    "\n",
    "def f1_score(pred_span, true_span):\n",
    "    pred_start, pred_end = pred_span\n",
    "    true_start, true_end = true_span\n",
    "\n",
    "    common = min(pred_end, true_end) - max(pred_start, true_start) + 1\n",
    "    if common <= 0:\n",
    "        return 0\n",
    "    precision = common / (pred_end - pred_start + 1)\n",
    "    recall = common / (true_end - true_start + 1)\n",
    "    return 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "def precision_score(pred_span, true_span):\n",
    "    pred_start, pred_end = pred_span\n",
    "    true_start, true_end = true_span\n",
    "    common = min(pred_end, true_end) - max(pred_start, true_start) + 1\n",
    "    return common / (pred_end - pred_start + 1) if common > 0 else 0\n",
    "\n",
    "def recall_score(pred_span, true_span):\n",
    "    pred_start, pred_end = pred_span\n",
    "    true_start, true_end = true_span\n",
    "    common = min(pred_end, true_end) - max(pred_start, true_start) + 1\n",
    "    return common / (true_end - true_start + 1) if common > 0 else 0\n",
    "\n",
    "\n",
    "#model = DebertaForQuestionAnswering.from_pretrained('microsoft/deberta-base')\n",
    "model = RobertaForQuestionAnswering.from_pretrained('roberta-base')\n",
    "\n",
    "model.load_state_dict(torch.load('RoBERTa_64_EM_78_F1.pth'))\n",
    "model.to(device)\n",
    "\n",
    "def load_data(file_path, subset_size=None):\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = [json.loads(line.strip()) for line in f if line.strip()]\n",
    "    \n",
    "        if subset_size is not None and subset_size < len(data):\n",
    "            data = random.sample(data, subset_size)\n",
    "        return data\n",
    "\n",
    "val_data = load_data('short_answers_only-dev.jsonl', 5000)\n",
    "\n",
    "val_loss, val_em, val_f1, val_precision, val_recall = evaluate(\n",
    "    model,\n",
    "    val_data,\n",
    "    batch_size=8,\n",
    "    max_length=256,\n",
    "    max_answers=1\n",
    ")\n",
    "\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Exact Match (EM): {val_em}\")\n",
    "print(f\"F1 Score: {val_f1}\")\n",
    "print(f\"Precision: {val_precision}\")\n",
    "print(f\"Recall: {val_recall}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
